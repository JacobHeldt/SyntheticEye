{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For OS interaction and system-specific parameters\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# PyTorch libraries\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, random_split, Dataset, WeightedRandomSampler, Subset\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "import cv2\n",
    "\n",
    "# Torchvision\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "import torchvision.datasets as datasets\n",
    "\n",
    "\n",
    "# Albumentations for Data Augmentation\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "\n",
    "# PIL for image operations\n",
    "from PIL import Image\n",
    "\n",
    "# Matplotlib for plotting and visualizations\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Import numpy\n",
    "import numpy as np\n",
    "\n",
    "# TensorBoard for PyTorch\n",
    "from tensorboardX import SummaryWriter\n",
    "\n",
    "# CodeCarbon for tracking our carbon emissions\n",
    "from codecarbon import EmissionsTracker\n",
    "\n",
    "# tqdm for showing progress bars\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# Import Netron for visualizing our model\n",
    "import netron\n",
    "\n",
    "# Add scripts to directory\n",
    "sys.path.append('/Users/jacob/OneDrive/Desktop/SyntheticEye/Development/src/utils')\n",
    "# Import custom helper functions from scripts directory\n",
    "import helper_functions"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gain Insights on Dataset\n",
    "This is so we can better understand our data and helps us to decide which fixed image size to choose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary function from helper_functions.py\n",
    "from helper_functions import plot_image_dimensions_bar_graph\n",
    "from helper_functions import plot_total_image_dimensions_bar_graph\n",
    "from helper_functions import plot_class_distribution\n",
    "from helper_functions import check_accuracy_aletheia4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot Image Dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting overall image dimensions\n",
    "img_dir = \"/Users/jacob/OneDrive/Argus4Dataset/\"\n",
    "plot_total_image_dimensions_bar_graph(img_dir, heading='Argus Dataset Image Dimensions')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting dimensions of cg-generated images\n",
    "img_dir = \"/Users/jacob/OneDrive/Argus4Dataset/real/\"\n",
    "plot_image_dimensions_bar_graph(img_dir, heading='Real Image Dimensions')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting dimensions of GAN images\n",
    "img_dir = \"/Users/jacob/OneDrive/Desktop/Aletheia4Dataset/ai/\"\n",
    "plot_image_dimensions_bar_graph(img_dir, heading='AI Image Dimensions')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot Class Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_class_distribution('/Users/jacob/OneDrive/Argus4Dataset/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from helper_functions import show_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomImageDataset(Dataset):\n",
    "    def __init__(self, img_directory, indices=None, transforms=None):\n",
    "        self.img_directory = img_directory\n",
    "        self.transforms = transforms\n",
    "        self.img_labels = []\n",
    "        self.img_names = []\n",
    "\n",
    "        # Iterate through classes\n",
    "        for class_id, class_name in enumerate(os.listdir(img_directory)):\n",
    "            class_dir = os.path.join(img_directory, class_name)\n",
    "            # Iterate through all images of a class\n",
    "            for img in os.listdir(class_dir):\n",
    "                if img.lower().endswith(('.png', '.jpg', '.jpeg', '.webp')):\n",
    "                    self.img_names.append(os.path.join(class_name, img))\n",
    "                    self.img_labels.append(class_id)\n",
    "\n",
    "        if indices is not None:\n",
    "            self.img_names = [self.img_names[i] for i in indices]\n",
    "            self.img_labels = [self.img_labels[i] for i in indices]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_names)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img_path = os.path.join(self.img_directory, self.img_names[index])\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "\n",
    "        # Apply transforms\n",
    "        if self.transforms:\n",
    "            image = np.array(image) \n",
    "            image = self.transforms(image=image)['image']\n",
    "\n",
    "        label = self.img_labels[index]\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from helper_functions import get_image_mean_std\n",
    "\n",
    "dataset_path = \"/Users/jacob/OneDrive/Argus4Dataset/\"\n",
    "\n",
    "mean, std = get_image_mean_std(dataset_path)\n",
    "print(mean)\n",
    "print(std)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply Data Augmentation\n",
    "We augment the images in our dataset to make sure our model is robust and to prevent overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transforms = A.Compose([\n",
    "    A.SmallestMaxSize(max_size=304), \n",
    "    A.CenterCrop(256, 256), \n",
    "    A.HorizontalFlip(p=0.5),\n",
    "    A.ShiftScaleRotate(shift_limit=0.05, scale_limit=0.03, rotate_limit=7, p=0.5),\n",
    "    A.PixelDropout(dropout_prob=0.01, p=0.35),\n",
    "    A.Normalize(mean=[0.4693, 0.4415, 0.4012], std=[0.2245, 0.2188, 0.2133]),\n",
    "    ToTensorV2()\n",
    "])\n",
    "\n",
    "test_transforms = A.Compose([\n",
    "    A.SmallestMaxSize(max_size=304), \n",
    "    A.CenterCrop(256, 256), \n",
    "    A.Normalize(mean=[0.4693, 0.4415, 0.4012], std=[0.2245, 0.2188, 0.2133]),\n",
    "    ToTensorV2()\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_images(dataset, images=12):\n",
    "    # Set up figure\n",
    "    fig, axes = plt.subplots(1, images, figsize=(images * 3, 3))\n",
    "    \n",
    "    for i in range(images):\n",
    "        # Get an image from dataset\n",
    "        image = dataset[i]\n",
    "        \n",
    "        # Convert image to numpy array\n",
    "        if torch.is_tensor(image):\n",
    "            image = image.numpy().transpose((1, 2, 0))\n",
    "\n",
    "        # Display the image\n",
    "        axes[i].imshow(image)\n",
    "        axes[i].axis('off')\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Dataset\n",
    "dataset = CustomImageDataset(\"/Users/jacob/OneDrive/Argus4Dataset/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_samples = len(dataset)\n",
    "print(f\"Number of samples in the dataset: {num_samples}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Weights for Classes in Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = 2\n",
    "\n",
    "def define_class_weights(labels, classes):\n",
    "    count = [0] * classes\n",
    "\n",
    "    # Count frequency of class labels\n",
    "    for label in labels:\n",
    "        count[label] += 1\n",
    "    class_weights = [0.] * classes\n",
    "\n",
    "    # Calculate number of samples in dataset\n",
    "    samples = float(sum(count))\n",
    "    \n",
    "    # Calculate weight for each class\n",
    "    for i in range(classes):\n",
    "        if count[i] == 0:\n",
    "            class_weights[i] = 0 \n",
    "        else:\n",
    "            class_weights[i] = samples / float(count[i])\n",
    "    weight = [class_weights[label] for label in labels]\n",
    "    return weight\n",
    "\n",
    "weights = define_class_weights(dataset.img_labels, classes)\n",
    "weights = torch.DoubleTensor(weights)\n",
    "sampler = WeightedRandomSampler(weights, len(dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set manual seed for reproducibility\n",
    "torch.manual_seed(42)\n",
    "\n",
    "# Split dataset into train, test, and validation sets\n",
    "train_size = int(0.85 * len(dataset))\n",
    "val_size = int(0.05 * len(dataset))\n",
    "test_size = len(dataset) - train_size - val_size\n",
    "train_dataset_i, val_dataset_i, test_dataset_i = random_split(range(len(dataset)), [train_size, val_size, test_size])\n",
    "\n",
    "# Apply transforms and create dataset instances for each split\n",
    "transformed_train_dataset = CustomImageDataset(\"/Users/jacob/OneDrive/Argus4Dataset/\", indices=train_dataset_i, transforms=train_transforms)\n",
    "transformed_val_dataset = CustomImageDataset(\"/Users/jacob/OneDrive/Argus4Dataset/\", indices=val_dataset_i, transforms=test_transforms)\n",
    "transformed_test_dataset = CustomImageDataset(\"/Users/jacob/OneDrive/Argus4Dataset/\", indices=test_dataset_i, transforms=test_transforms)\n",
    "\n",
    "# Extract labels for the training set\n",
    "train_labels = [transformed_train_dataset.img_labels[i] for i in range(len(transformed_train_dataset))]\n",
    "\n",
    "# Calculate weights for the training set\n",
    "weights = define_class_weights(train_labels, classes)\n",
    "weights = torch.DoubleTensor(weights)\n",
    "\n",
    "# Create a sampler for the training set\n",
    "sampler = WeightedRandomSampler(weights, len(weights))\n",
    "\n",
    "# Create DataLoaders for each dataset split\n",
    "train_loader = DataLoader(transformed_train_dataset, batch_size=32, sampler=sampler, shuffle=False)\n",
    "val_loader = DataLoader(transformed_val_dataset, batch_size=64, shuffle=False)\n",
    "test_loader = DataLoader(transformed_test_dataset, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(transformed_train_dataset.__len__())\n",
    "print(transformed_val_dataset.__len__())\n",
    "print(transformed_test_dataset.__len__())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Sample Image With Transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define transformations\n",
    "train_transforms = A.Compose([\n",
    "    A.SmallestMaxSize(max_size=304), \n",
    "    A.CenterCrop(256, 256), \n",
    "    A.HorizontalFlip(p=1),\n",
    "    A.ShiftScaleRotate(shift_limit=0.05, scale_limit=0.05, rotate_limit=10, p=1),\n",
    "    A.PixelDropout(dropout_prob=0.015, p=1),\n",
    "])\n",
    "\n",
    "img = cv2.imread(\"C:\\\\Users\\\\jacob\\\\OneDrive\\\\Desktop\\\\SyntheticEye\\\\SampleData\\\\AI\\\\030CHMXYM3.jpg\") \n",
    "img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)  \n",
    "\n",
    "# Apply transformations\n",
    "transformed = train_transforms(image=img)\n",
    "transformed_img = transformed[\"image\"]\n",
    "\n",
    "# Plot original and transformed image \n",
    "plt.figure(figsize=(24, 12))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.title('Original Image')\n",
    "plt.imshow(img)\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.title('Transformed Image')\n",
    "plt.imshow(transformed_img)\n",
    "plt.axis('off')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResBlock5(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, dropout_prob=0.05): \n",
    "        super(ResBlock5, self).__init__()\n",
    "\n",
    "        # 3x3 convolutions\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, 3, padding=1),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Dropout(dropout_prob),\n",
    "            nn.Conv2d(out_channels, out_channels, 3, padding=1),\n",
    "            nn.BatchNorm2d(out_channels)\n",
    "        )\n",
    "\n",
    "        # Define skip connection\n",
    "        self.residual = nn.Conv2d(in_channels, out_channels, 1, padding=0) if in_channels != out_channels else nn.Identity()\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.conv(x)\n",
    "        res = self.residual(x)\n",
    "        return F.leaky_relu(out + res)  \n",
    "\n",
    "class Argus5Net(nn.Module):\n",
    "    def __init__(self, dropout_prob=0.35): \n",
    "        super(Argus5Net, self).__init__()\n",
    "\n",
    "        # Convolutional layers with simplified residual blocks and max-pooling\n",
    "        self.conv_layers = nn.Sequential(\n",
    "            ResBlock5(3, 16, dropout_prob=0.05),\n",
    "            nn.MaxPool2d(2),\n",
    "            ResBlock5(16, 32, dropout_prob=0.05),\n",
    "            nn.MaxPool2d(2),\n",
    "            ResBlock5(32, 64, dropout_prob=0.05),\n",
    "            nn.MaxPool2d(2),\n",
    "            ResBlock5(64, 128, dropout_prob=0.05)\n",
    "        )\n",
    "\n",
    "        # Global Average Pooling\n",
    "        self.global_avg_pool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "\n",
    "        # Fully connected layers\n",
    "        self.fc_layers = nn.Sequential(\n",
    "            nn.Linear(128, 256), \n",
    "            nn.LeakyReLU(),\n",
    "            nn.Dropout(dropout_prob),\n",
    "            nn.Linear(256, 1) \n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv_layers(x)\n",
    "        x = self.global_avg_pool(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc_layers(x)\n",
    "        return x"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Up Device Agnostic Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set device to GPU if available, else use the CPU\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Device: {device}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparamters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Hyperparameters\n",
    "num_classes = 2\n",
    "learning_rate = 0.0005\n",
    "batch_size = 32\n",
    "num_epochs = 12"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare Training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set random seed for reproducibility and initialize model\n",
    "torch.manual_seed(42)\n",
    "model = Argus5Net().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_function = torch.nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate, weight_decay=0.0005)\n",
    "# Define learning rate scheduler to automatically adjust our learning rate\n",
    "scheduler = StepLR(optimizer, step_size=1, gamma=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize TensorBoard\n",
    "writer = SummaryWriter(f'runs/Argus5_1')\n",
    "step = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from helper_functions import check_accuracy"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Argus5Net().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.cuda.amp import GradScaler, autocast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "carbon_tracker = EmissionsTracker(project_name=\"Argus5\", log_level=\"critical\")\n",
    "carbon_tracker.start()\n",
    "\n",
    "torch.manual_seed(42)\n",
    "\n",
    "model = model.to(device)\n",
    "\n",
    "metrics_interval = 100\n",
    "\n",
    "# Start training\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    train_progress = tqdm(enumerate(train_loader), total=len(train_loader))\n",
    "    for batch_idx, (inputs, labels) in train_progress:\n",
    "        inputs, labels = inputs.to(device), labels.float().to(device)  \n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(inputs).squeeze()  \n",
    "        loss = loss_function(outputs, labels)\n",
    "\n",
    "        # Backward pass and optimization\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        predicted = torch.sigmoid(outputs) > 0.5  \n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "        if (batch_idx + 1) % metrics_interval == 0:\n",
    "            writer.add_scalar('Training Loss', running_loss / metrics_interval, epoch * len(train_loader) + batch_idx)\n",
    "            writer.add_scalar('Training Accuracy', 100 * correct / total, epoch * len(train_loader) + batch_idx)\n",
    "            # Print training results\n",
    "            print(f'Epoch {epoch}, Batch {batch_idx+1}, Training Accuracy: {100 * correct / total:.2f}%', flush=True)\n",
    "            # Reset values\n",
    "            running_loss = 0.0\n",
    "            correct = 0\n",
    "            total = 0\n",
    "\n",
    "    # Validation\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in val_loader:\n",
    "            inputs, labels = inputs.to(device), labels.float().to(device)  # Adjust labels dtype for BCEWithLogitsLoss\n",
    "            outputs = model(inputs).squeeze()  \n",
    "            loss = loss_function(outputs, labels)\n",
    "            val_loss += loss.item()\n",
    "            predicted = torch.sigmoid(outputs) > 0.5 \n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    val_loss /= len(val_loader)\n",
    "    val_accuracy = 100 * correct / total\n",
    "    writer.add_scalar('Validation Loss', val_loss, epoch)\n",
    "    writer.add_scalar('Validation Accuracy', val_accuracy, epoch)\n",
    "\n",
    "    # Print validation results\n",
    "    print(f'Epoch {epoch}, Validation Loss: {val_loss:.4f}, Validation Accuracy: {val_accuracy:.2f}%')\n",
    "\n",
    "    # Scheduler step\n",
    "    scheduler.step()\n",
    "\n",
    "    # Save model checkpoint\n",
    "    torch.save(model.state_dict(), f'Argus4_1{epoch}.pth')\n",
    "\n",
    "# Finalize carbon tracking\n",
    "emissions = carbon_tracker.stop()\n",
    "print(f\"Emissions: {emissions:.5f} kgCO2eq\")\n",
    "\n",
    "# Close TensorBoard writer\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = GradScaler()\n",
    "\n",
    "carbon_tracker = EmissionsTracker(project_name=\"Argus5_1\", measure_power_secs=600)\n",
    "carbon_tracker.start()\n",
    "\n",
    "torch.manual_seed(42)\n",
    "\n",
    "model = model.to(device)\n",
    "\n",
    "metrics_interval = 50\n",
    "\n",
    "# Start training\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    train_progress = tqdm(enumerate(train_loader), total=len(train_loader))\n",
    "    for batch_idx, (inputs, labels) in train_progress:\n",
    "        inputs, labels = inputs.to(device), labels.float().to(device)  \n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Use autocast to improve training efficiency\n",
    "        with autocast():\n",
    "            outputs = model(inputs).squeeze() \n",
    "            loss = loss_function(outputs, labels)\n",
    "\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "\n",
    "        scaler.update()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        predicted = torch.sigmoid(outputs.detach()) > 0.5 \n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "        if (batch_idx + 1) % metrics_interval == 0:\n",
    "            writer.add_scalar('Training Loss', running_loss / metrics_interval, epoch * len(train_loader) + batch_idx)\n",
    "            writer.add_scalar('Training Accuracy', 100 * correct / total, epoch * len(train_loader) + batch_idx)\n",
    "            print(f'Epoch {epoch}, Batch {batch_idx+1}, Training Accuracy: {100 * correct / total:.2f}%', flush=True)\n",
    "            running_loss = 0.0\n",
    "            correct = 0\n",
    "            total = 0\n",
    "\n",
    "    # Validation\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in val_loader:\n",
    "            inputs, labels = inputs.to(device), labels.float().to(device)\n",
    "            outputs = model(inputs).squeeze()\n",
    "            loss = loss_function(outputs, labels)\n",
    "            val_loss += loss.item()\n",
    "            predicted = torch.sigmoid(outputs) > 0.5\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    val_loss /= len(val_loader)\n",
    "    val_accuracy = 100 * correct / total\n",
    "    writer.add_scalar('Validation Loss', val_loss, epoch)\n",
    "    writer.add_scalar('Validation Accuracy', val_accuracy, epoch)\n",
    "    print(f'Epoch {epoch}, Validation Loss: {val_loss:.4f}, Validation Accuracy: {val_accuracy:.2f}%')\n",
    "\n",
    "    scheduler.step()\n",
    "    torch.save(model.state_dict(), f'Argus5_1_1_{epoch}.pth')\n",
    "\n",
    "emissions = carbon_tracker.stop()\n",
    "print(f\"Emissions: {emissions:.5f} kgCO2eq\")\n",
    "\n",
    "writer.close()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Argus5Net().to(device)\n",
    "\n",
    "\n",
    "sample_input = torch.randn(1, 3, 256, 256).to(device)\n",
    "model(sample_input)\n",
    "\n",
    "# Specify path to the trained model weights\n",
    "model_path = \"C:\\\\Users\\\\jacob\\\\OneDrive\\\\Desktop\\\\SyntheticEye\\\\Development\\\\src\\\\models\\\\Argus5_1_6.pth\"\n",
    "model.load_state_dict(torch.load(model_path))\n",
    "\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check accuracy of trained model on the test data\n",
    "check_accuracy(train_loader, model, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Argus5Net().to(device)\n",
    "\n",
    "sample_input = torch.randn(1, 3, 256, 256).to(device)\n",
    "model(sample_input)\n",
    "\n",
    "# Load model\n",
    "model_path = \"C:\\\\Users\\\\jacob\\\\OneDrive\\\\Desktop\\\\SyntheticEye\\\\Development\\\\src\\\\models\\\\Argus5_1_0.pth\"\n",
    "model.load_state_dict(torch.load(model_path))\n",
    "\n",
    "model = model.to(device)\n",
    "\n",
    "# Ensure model is in evaluation mode\n",
    "model.eval()\n",
    "\n",
    "# Move model to the appropriate device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "model.eval()\n",
    "\n",
    "all_preds = []\n",
    "all_true_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in tqdm(val_loader, desc=\"Evaluating\"):\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        outputs = model(inputs)\n",
    "        probabilities = torch.sigmoid(outputs).squeeze()  # Sigmoid to convert to probabilities\n",
    "        predicted = torch.round(probabilities) \n",
    "        all_preds.extend(predicted.cpu().numpy())\n",
    "        all_true_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "precision = precision_score(all_true_labels, all_preds, average='binary')\n",
    "print(f\"Precision for class: {precision}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "netron.start(\"C:\\\\Users\\\\jacob\\\\OneDrive\\\\Desktop\\\\SyntheticEye\\\\Development\\\\Aletheia4_3_epoch_16.pth\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
